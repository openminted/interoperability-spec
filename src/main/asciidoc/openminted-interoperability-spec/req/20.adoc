== Workflow engines should not require to see data

[%hardbreaks]
[small]#*_Concreteness:_* __concrete__#
[small]#*_Strength:_*     __recommended__#
[small]#*_Category:_*     __WG2__,__WG4__#
[small]#*_Status:_*       __deprecated__#

IMPORTANT: This requirement has been deprecated. It continues to exist as the functional requirement FS/WFEX/07.

When assembling a workflow and running it, the workflow engine should not require that all data be transferred between the components by passing it through the engine. In the best case, this would only incur a performance overhead. In the worst case, it would require potentially sensitive or proprietary data to leave its source infrastructure, even if the actual analysis components deployed would be deployed on the same infrastructure (that is assuming that the workflow engine does not also run on the same infrastructure). This could e.g. be solved by processing components talking directly to each other.

Source: WG1 Scenario 2 â€” SME running research analytics for funders within the European Research Area

// Below is an example of how a compliance evaluation table could look. This is presently optional
// and may be moved to a more structured/principled format later maintained in separate files.
[cols="2,1,1,4,1"]
|====
|Product|Version|Compliant|Justification|Status

| Alvis
| 0.5rc
| Partial
| Alvis uses a shared data structure, the workflow engine is required to manage the data and the modules during the execution steps. However the Alvis modules could be encapsulated with the Alvis engine in a OpenMinTeD workflow.
| Draft

| ARGO
| 0.5
| Partial
| On certain infrastructures with shared storage, it is possible for data to bypass the workflow engine.  The Argo development roadmap does contain a plan to allow components to be speak directly to one another.
| Draft

| DKPro Core
| 1.8.0
| N/A
| DKPro Core itself does not provide workflow functionality. It's components can in principle be used in a workflow setup where data is passed directly between components, i.e. without going through a central workflow manager. But providing such a manager is beyond the scope of DKPro Core.
| Draft

| GATE
| 8.2
| Partial
| GATE components don't talk to each other, passing data is the job of a pipeline (which is akin to a workflow). However, if within an OpenMinTeD workflow there were a sequence of GATE components then these could be aggregated into a GATE pipeline and deployed as a single unit meaning that data would be kept within the pipeline.
| Draft

| ILSP
| 1.2.1
| Partial
| For ILSP components deployed as UIMA AS services, data to be transferred from, say, component A to component B that are remotely deployed on node X are not first passed through a message broker running on node Y
| Draft
|====
